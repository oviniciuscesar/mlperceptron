Network Structure:
Parameters: 5
Number of layers: 3
3 6 10 5 2 
Activation Functions:
relu sofplus softmax 
Hyperparameters:
Learning rate: 0.01
Max epochs: 1000
Current epoch: 1000
Training mode: 0
Data size: 20
Error: 250001
Layer 1 Weights:
0.636575 0.154602 -1.36074 0.282044 0.238653 -0.427876 
-0.886306 0.686272 -2.45007 0.10379 0.508721 -0.952622 
-0.256695 -3.68725 -0.45839 -0.580926 2.3709 -2.08484 
0.169494 -1.77362 -0.115189 0.572317 -2.95012 0.742227 
-2.28486 0.537942 -1.53658 0.879411 0.430649 1.88864 
-0.97065 0.330038 -1.00976 -0.385446 1.24692 -0.0346747 
1.52069 0.106875 0.84888 1.16588 1.40314 -1.08725 
2.2923 0.707027 -0.550938 -0.817189 0.277435 -0.246019 
1.35719 1.52588 -0.640671 0.74934 -0.463491 -0.459357 
0.364295 -2.02832 0.756452 -2.13876 3.37847 1.04317 
Layer 2 Weights:
-0.244829 2.07418 -3.20886 -1.8667 -0.13292 -1.25114 -1.12538 -1.39908 1.49203 2.62728 
0.228129 0.312462 -0.604295 -1.31779 1.03846 0.589223 0.597245 1.50894 0.700197 1.89477 
0.140227 0.617849 1.04661 -0.104558 -0.138117 0.835398 0.545896 -1.0588 -0.290963 -1.34259 
1.18907 1.9139 0.447044 2.49231 -1.96994 1.17239 -1.25318 -0.194736 -0.80322 2.69089 
-0.934637 -0.51571 3.3148 1.36243 -3.01015 1.08214 1.53123 1.19457 -1.80913 -1.8069 
Layer 3 Weights:
-4.84688 2.9424 -1.19046 -3.17253 2.56747 
4.48066 -3.15792 2.58925 2.39993 -3.93301 
Layer 1 Bias:
0.573029 1.19558 0.241794 -0.760452 1.48824 -0.614314 0.0903993 0.629254 -0.590733 1.16387 
Layer 2 Bias:
1.15043 0.452113 -0.184147 0.143829 -0.595145 
Layer 3 Bias:
0.601583 -0.587627 
