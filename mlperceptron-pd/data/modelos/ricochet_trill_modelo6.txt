Network Structure:
Parameters: 5
Number of layers: 3
3 6 10 5 2 
Activation Functions:
relu sofplus softmax 
Hyperparameters:
Learning rate: 0.04
Max epochs: 1000
Current epoch: 1000
Training mode: 0
Data size: 20
Error: 315389
Layer 1 Weights:
1.05907 0.577396 -0.280836 -0.308579 0.415745 0.098421 
-1.18132 2.24513 -1.48277 0.453226 -0.173141 -1.64358 
-0.388479 0.184174 -1.20599 -0.15896 -0.0724558 1.20286 
1.87125 -0.942317 -0.453493 0.40903 -2.55454 0.0448182 
-0.847129 -0.86388 -0.930809 -0.0321579 3.45497 0.0362838 
0.230863 2.62667 -1.68155 1.81788 -0.275942 1.57397 
1.97512 -0.686673 1.70663 -1.13081 1.56942 -1.13311 
-0.762685 -1.67656 3.10674 0.231666 0.43842 1.66015 
0.390746 -0.253707 3.4302 3.19407 -3.83219 1.08957 
0.605272 -3.42128 0.290044 -1.26133 -1.69444 -2.21772 
Layer 2 Weights:
-0.496313 3.04855 -1.9573 0.902148 -2.27072 -3.37389 0.265036 2.21005 2.76756 -3.27016 
1.04664 0.782986 -0.56694 1.23206 -0.737496 -0.00882874 0.678543 -1.67252 0.044345 0.999018 
0.195958 -1.01884 0.300346 -2.4011 1.8585 0.133843 1.672 0.420473 3.3316 -0.169362 
0.383365 0.921366 0.823745 0.713148 -2.24072 -0.72875 -1.47179 0.381696 -4.94988 -2.8662 
0.608117 -0.386308 -1.27249 1.3255 1.43573 0.130896 1.65074 -2.42615 0.162735 2.29764 
Layer 3 Weights:
-6.20611 0.49875 3.63889 -5.58266 2.31494 
5.99127 0.675076 -5.14288 4.06789 -1.05233 
Layer 1 Bias:
-0.212115 0.617907 1.98925 -0.255317 -1.86922 1.39301 0.592382 -0.795098 -2.53015 -2.29302 
Layer 2 Bias:
-1.27339 -0.414077 -0.0263076 1.40469 -0.163994 
Layer 3 Bias:
-1.54368 1.55156 
