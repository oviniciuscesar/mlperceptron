Network Structure:
Parameters: 5
Number of layers: 3
3 6 10 5 2 
Activation Functions:
relu sofplus softmax 
Hyperparameters:
Learning rate: 0.04
Max epochs: 500
Current epoch: 500
Training mode: 0
Data size: 20
Error: 90.1567
Layer 1 Weights:
0.198872 1.01033 -1.56127 -2.15475 2.34199 0.988683 
-0.282219 -1.5171 -0.0702254 -1.23185 1.84481 0.986129 
-0.764255 0.603906 1.46034 0.949372 -3.33342 0.662677 
-0.52845 -4.69994 -0.420347 -0.605185 3.5234 -2.6546 
0.383425 -1.25078 3.09425 -0.896275 -0.76561 0.687968 
2.16363 0.531068 -0.231559 -1.14966 -1.22718 -2.37267 
-2.80661 0.687992 0.650584 0.36252 0.665701 -0.252659 
1.31423 -0.724765 1.26663 1.36834 1.65779 -1.39908 
-1.34617 0.0503745 -0.924132 1.15254 -1.28728 0.817316 
1.7754 -1.69615 0.71448 -2.38062 -0.909101 -0.863451 
Layer 2 Weights:
-0.488223 1.03162 -0.795011 -0.113543 0.00743136 -0.862906 -0.0996623 -0.626916 0.0324318 -0.980717 
2.31544 1.0918 1.09621 -0.908912 0.716423 -0.525486 -1.81257 1.23169 0.632391 -0.231323 
-0.653146 -1.19914 0.303796 1.6437 -0.813644 1.88574 -0.411072 0.659755 -0.24068 2.13867 
1.75905 1.96469 -3.61058 -3.96772 0.0289087 -0.984593 1.79338 -1.93308 -2.13082 -0.403879 
-3.15028 -0.506039 0.525209 -2.74662 3.07287 -2.20214 0.438687 0.962328 -0.0482382 -2.93815 
Layer 3 Weights:
-1.05195 2.93084 1.44342 -4.84555 -4.23306 
-0.0173451 -4.50983 -1.4232 4.73936 5.61105 
Layer 1 Bias:
2.8811 1.37153 -0.426368 -0.593951 -1.71811 -0.0977615 -0.319778 -0.105222 -0.256548 -1.01618 
Layer 2 Bias:
-0.098189 0.449016 -1.01129 1.75341 -0.785519 
Layer 3 Bias:
-2.03348 2.03622 
